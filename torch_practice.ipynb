{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method type of Tensor object at 0x000002CBE6F96270>\n",
      "torch.Size([2, 2, 2, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.7042, -2.1602],\n",
       "          [-1.4712,  0.2900]],\n",
       "\n",
       "         [[-0.3257,  0.4281],\n",
       "          [ 0.3159,  0.2721]]],\n",
       "\n",
       "\n",
       "        [[[-0.7300, -0.9016],\n",
       "          [-2.3673, -0.4627]],\n",
       "\n",
       "         [[-1.3425,  0.6196],\n",
       "          [-0.4664,  1.3314]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a 4d tensor and print it.\n",
    "x = torch.randn(2,2,2,2, dtype=torch.float32)\n",
    "print(x.type)\n",
    "print(x.size())\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a tensor from a list.\n",
    "y = torch.tensor([2,3])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addition in pytorch:\n",
    "# \"z = x + y\" \"z = torch.add(x,y)\" will add element-wise\n",
    "# \"y.add_(x)\" will perform addition in-place. In torch _ indicated in-place operation.\n",
    "\n",
    "#Similarly sub, mul and div can be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3257,  0.4281],\n",
      "         [ 0.3159,  0.2721]],\n",
      "\n",
      "        [[-1.3425,  0.6196],\n",
      "         [-0.4664,  1.3314]]])\n",
      "tensor([[-1.3425,  0.6196],\n",
      "        [-0.4664,  1.3314]])\n"
     ]
    }
   ],
   "source": [
    "#Sllicing of tensors:\n",
    "print(x[:,1]) # Print all rows of column 1\n",
    "print(x[1,1]) # Print element at 1,1. When it holds only one item, we can use .item() to get the exact value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7042, -2.1602, -1.4712,  0.2900, -0.3257,  0.4281,  0.3159,  0.2721],\n",
       "        [-0.7300, -0.9016, -2.3673, -0.4627, -1.3425,  0.6196, -0.4664,  1.3314]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Resizing a tensor\n",
    "x_new = x.view(-1,8) #When we give -1, the second dimension is automatically figured out\n",
    "print(x_new.shape)\n",
    "x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[[[ 1.7041695  -1.1601868 ]\n",
      "   [-0.47115052  1.290018  ]]\n",
      "\n",
      "  [[ 0.6743277   1.4280651 ]\n",
      "   [ 1.3159142   1.2720963 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.2699811   0.09837598]\n",
      "   [-1.367326    0.53727686]]\n",
      "\n",
      "  [[-0.34254873  1.6195933 ]\n",
      "   [ 0.5335721   2.3314047 ]]]]\n",
      "tensor([[[[ 1.7042, -1.1602],\n",
      "          [-0.4712,  1.2900]],\n",
      "\n",
      "         [[ 0.6743,  1.4281],\n",
      "          [ 1.3159,  1.2721]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2700,  0.0984],\n",
      "          [-1.3673,  0.5373]],\n",
      "\n",
      "         [[-0.3425,  1.6196],\n",
      "          [ 0.5336,  2.3314]]]])\n"
     ]
    }
   ],
   "source": [
    "#Numpy to tensor and vice-versa:\n",
    "import numpy as np\n",
    "\n",
    "x_np = x.numpy() #Only allowed in CPU not on GPU\n",
    "print(type(x_np))\n",
    "\n",
    "#Be careful if both are in cpu memory, because if one is modiefied other will also get changes. As both are pointing to same memory.\n",
    "x.add_(1)\n",
    "print(x_np)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "x_back_to_torch = torch.from_numpy(x_np)\n",
    "print(type(x_back_to_torch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9816, -0.7457, -0.2961], requires_grad=True)\n",
      "tensor([1.0184, 1.2543, 1.7039], grad_fn=<AddBackward0>)\n",
      "tensor(5.5135, grad_fn=<MeanBackward0>)\n",
      "tensor([2.0369, 2.5085, 3.4077])\n"
     ]
    }
   ],
   "source": [
    "#autograd:\n",
    "a = torch.randn(3, requires_grad=True)\n",
    "print(a)\n",
    "\n",
    "b = a+2\n",
    "print(b)\n",
    "\n",
    "c = b*b*3\n",
    "c = c.mean()\n",
    "print(c)\n",
    "\n",
    "c.backward() #Pass argument if c is not a scaler vector.\n",
    "print(a.grad)\n",
    "#print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Following are 3 ways to stop torch to track gradients:\n",
    "#a.requires_grad_(False)\n",
    "#a.detach_()\n",
    "#with torch.no_grad():\n",
    "    #Do some ops without grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights.grad.zero_(): This will help avoid accumulation of grad in backward function while training with multiple epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "for Epoch 1 : Weight = 2.849 and loss = 13.745262\n",
      "for Epoch 11 : Weight = 2.041 and loss = 0.005612\n",
      "for Epoch 21 : Weight = 2.019 and loss = 0.000566\n",
      "for Epoch 31 : Weight = 2.014 and loss = 0.000308\n",
      "for Epoch 41 : Weight = 2.010 and loss = 0.000167\n",
      "for Epoch 51 : Weight = 2.008 and loss = 0.000091\n",
      "for Epoch 61 : Weight = 2.006 and loss = 0.000050\n",
      "for Epoch 71 : Weight = 2.004 and loss = 0.000027\n",
      "for Epoch 81 : Weight = 2.003 and loss = 0.000015\n",
      "for Epoch 91 : Weight = 2.002 and loss = 0.000008\n",
      "Prediction = 10.004\n"
     ]
    }
   ],
   "source": [
    "#Example model with pytorch functions:\n",
    "import torch.nn as nn\n",
    "\n",
    "EPOCHS = 100\n",
    "LR = 0.1\n",
    "\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor([5], dtype=torch.float32)\n",
    "\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "in_shape = out_shape = n_features\n",
    "print(in_shape, out_shape)\n",
    "\n",
    "\n",
    "class LinReg (nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinReg, self).__init__()\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.lin(x)\n",
    "\n",
    "\n",
    "model = LinReg(in_shape, out_shape)\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "\n",
    "#Training\n",
    "for i in range(EPOCHS):\n",
    "    \n",
    "    y_pred = model(X)\n",
    "    \n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    l.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        [w,b] = model.parameters()\n",
    "        print(f\"for Epoch {i+1} : Weight = {w[0][0].item():.3f} and loss = {l:8f}\")\n",
    "\n",
    "#Test after training:\n",
    "print(f\"Prediction = {model(X_test).item():.3f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "21e725f0765fabd62c8620bbbf92ef947d48bcd7feb408ca2ff19b1cab4df46b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
